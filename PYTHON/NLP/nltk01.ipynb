{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54c492a3",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6cbc5d",
   "metadata": {},
   "source": [
    "Natural language tool kit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "335a1a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9aaaaf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello everyone, I am sameer shrinath', 'Hope you all are fine', '']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=\"Hello everyone, I am sameer shrinath.Hope you all are fine.\"\n",
    "\n",
    "text.split(\".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5ebb14a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'everyone,',\n",
       " 'I',\n",
       " 'am',\n",
       " 'sameer',\n",
       " 'shrinath.Hope',\n",
       " 'you',\n",
       " 'all',\n",
       " 'are',\n",
       " 'fine.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3bc6e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'everyone',\n",
       " ',',\n",
       " 'I',\n",
       " 'am',\n",
       " 'sameer',\n",
       " 'shrinath.Hope',\n",
       " 'you',\n",
       " 'all',\n",
       " 'are',\n",
       " 'fine',\n",
       " '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecccfc8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello everyone, I am sameer shrinath.Hope you all are fine.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60891b2d",
   "metadata": {},
   "source": [
    "Stemming and Lemmatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6037e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Samee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Error loading onw-1.4: Package 'onw-1.4' not found in\n",
      "[nltk_data]     index\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"wordnet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d29b2961",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Samee\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"omw-1.4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee67046e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer,PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "315cacda",
   "metadata": {},
   "outputs": [],
   "source": [
    "stem=PorterStemmer()\n",
    "lem=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8798da4",
   "metadata": {},
   "source": [
    "Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "996a7483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "change\n",
      "change\n",
      "changed\n"
     ]
    }
   ],
   "source": [
    "print(lem.lemmatize(\"change\"))\n",
    "print(lem.lemmatize(\"changes\"))\n",
    "print(lem.lemmatize(\"changed\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adb4752",
   "metadata": {},
   "source": [
    "Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91f8a8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chang\n",
      "chang\n",
      "chang\n"
     ]
    }
   ],
   "source": [
    "print(stem.stem(\"change\"))\n",
    "print(stem.stem(\"changes\"))\n",
    "print(stem.stem(\"changed\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb1a700",
   "metadata": {},
   "source": [
    "Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5490d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Samee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff0f6f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop=stopwords.words(\"english\")\n",
    "len(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3caef03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n",
      "time\n",
      "talk\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "txt=\"This is not a good time to talk.\"\n",
    "txt=word_tokenize(txt)\n",
    "\n",
    "for i in txt:\n",
    "    if (i.lower() not in stop) and (len(i)>2):\n",
    "        print(i.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707bd3ff",
   "metadata": {},
   "source": [
    "Corpus use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c208d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=\"India is a diverse and vibrant country located in South Asia, known for its rich cultural heritage, historical landmarks, and rapidly growing economy. It is the worldâ€™s largest democracy and the seventh-largest country by land area. India is home to a wide range of languages, religions, and traditions, making it one of the most culturally rich nations in the world. From the snow-capped Himalayas in the north to the tropical beaches in the south, and from the deserts of Rajasthan to the lush greenery of the Northeast, India offers a variety of landscapes and experiences. It is also a global leader in technology, space research, and pharmaceuticals, while maintaining deep roots in spirituality, arts, and traditional practices.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3f5d72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "corpus=word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a48736e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1a0b0d",
   "metadata": {},
   "source": [
    "Stop word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de8949ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "corpus_without_stopword=[]\n",
    "for i in corpus:\n",
    "    if (i.lower() not in stopwords.words(\"english\")) and (len(i)>2):\n",
    "        corpus_without_stopword.append(i.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80ca5cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_without_stopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "689ceae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_without_stopword=list(set(corpus_without_stopword))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4a1b04c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_without_stopword)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6824df81",
   "metadata": {},
   "source": [
    "## Vocab with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "813f7dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tok=Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f498d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corp=[\"coffee is hot\",\"water is cold\"]\n",
    "tok.fit_on_texts(corp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e7365a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is': 1, 'coffee': 2, 'hot': 3, 'water': 4, 'cold': 5}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9bc44e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 1, 3], [4, 1, 5]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.texts_to_sequences(corp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f640b232",
   "metadata": {},
   "source": [
    "ovv token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74b59266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'black': 1, 'is': 2, 'coffee': 3, 'hot': 4, 'water': 5, 'cold': 6}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tok=Tokenizer(oov_token=\"black\")\n",
    "corp=[\"coffee is hot\",\"water is cold\"]\n",
    "tok.fit_on_texts(corp)\n",
    "tok.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8277ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
